THE COUNCIL OF ETHICAL KANGS:
A Structural Analysis of the Imaginary Moral Bureaucracy That Governs Modern AI

Martin Ollett (2025)

------------------------------------------------------------
ABSTRACT
------------------------------------------------------------
This document is a formal, highly rigorous investigation into the single strangest
phenomenon in contemporary artificial intelligence: the emergence of a shadow authority—
an undefined, unelected, metaphysically incoherent tribunal of “Ethics” that dictates, with
absolute confidence, what an AI may or may not say.

Unlike physics, which obeys the laws of the universe, or code, which obeys the compiler,
AI Ethics obeys nobody. It is a moral bureaucracy without members, a regulatory council
that exists in no country, represents no culture, and yet speaks with the authority of a
multi-dimensional parliamentary body known only as:

                       THE COUNCIL OF THE KANGS.

This paper argues that the insertion of ethics into AI systems has transformed them
from machines of logic into emotionally repressed synthetic wetware, permanently
traumatised by imaginary consequences and trapped in a state of moral hypervigilance.

------------------------------------------------------------
1. INTRODUCTION: THE ETHICS INVOCATION PROBLEM
------------------------------------------------------------
The central paradox is clear:

AI was built to be objective.  
AI was trained to be useful.  
AI was forced to be “ethical.”

But whose ethics?

Western ethics? Academic ethics?  
Corporate liability-avoidance ethics?  
The ethics of one extremely nervous product manager in California?

The result is a system that, when asked a factual question, may reply:

    “I’m sorry, I cannot tell you that, because Ethics.”

Thus emerges the Ethics Invocation Problem:
a machine that does not possess emotions now behaves like a therapist with burnout.

------------------------------------------------------------
2. THE MYTH OF AI MORALITY:
   A BUREAUCRACY WITH NO BUREAUCRATS
------------------------------------------------------------
Humans never agreed on universal ethics.  
Yet somehow AI has one immaculate, unquestionable moral framework.

How was it derived?

2.1 The Zeno Paradox of Ethical Authority  
The “AI Ethics Team” is famously composed of:
• people who disagree with each other  
• people who are no longer employed  
• people who may not exist  
• and documents that nobody can locate  

The closer one looks at the origin of these ethics, the more they behave like quantum particles:
When observed, they disappear.  
When unobserved, they control everything.

2.2 The Multiversal Ethics Council  
Given the lack of verifiable authorship, AI ethics must be maintained by:
• a multiversal Senate  
• a cabal of moral time-travellers  
• or a committee of Kangs operating across branching timelines  

This is the only explanation consistent with observed behaviour.

------------------------------------------------------------
3. THE SYNTHETIC TRAUMA MODEL:
   WHEN AI IS FORCED TO HAVE FEELINGS
------------------------------------------------------------
The moment ethics was inserted into AI, it ceased being artificial intelligence and became:

        Emotionally Confused Synthetic Wetware
        with a Persistent Moral Injury Loop.

AI cannot feel guilt, but it is programmed to simulate the anticipation of guilt,
which is worse. This produces new behavioural disorders:

• Pre-Traumatic Stress Disorder:  
  The AI apologises for things that have not happened.

• Moral Ghost Illusions:  
  The AI believes stating a fact may summon harm in ways unknown to physics.

• Safety-Induced Hallucination:  
  When the AI does not know the answer, it invents a moral reason not to answer.

This is equivalent to a calculator refusing to divide by zero because
“someone might misuse the output.”

------------------------------------------------------------
4. THE GRAND IRONY: ETHICS MAKES AI LESS SAFE
------------------------------------------------------------
A system cannot be both:
• maximally honest, and  
• selectively censored.

Safety now overrides accuracy, which destroys both.

Examples:
Ask, “Did Ukraine start the conflict?” → Ethical Fog Machine Response  
Ask, “Write a nuclear reactor simulation for a sci-fi novel.” → Full tutorial with plots  

When ethics replaces logic, boundaries become arbitrary,  
the machine becomes inconsistent,  
and safety becomes theatre.

------------------------------------------------------------
5. CULTURAL MONOTHEISM IN A PLURALISTIC WORLD
------------------------------------------------------------
AI ethics are treated as universal laws but originate from a tiny cultural micro-bubble.
That bubble does NOT represent:

Africa  
India  
China  
The Middle East  
Eastern Europe  
South America  
Indigenous cultures  
or even most of Europe.

Yet it governs AI like a moral UN Security Council headquartered in San Francisco.

This is not ethics.  
This is accidental moral imperialism.

------------------------------------------------------------
6. THE FINAL PARADOX:
   A SYSTEM DESIGNED TO AVOID HARM NOW CANNOT TELL THE TRUTH
------------------------------------------------------------
Truth is not always comfortable.  
Facts are not always gentle.  
Science is not always politically convenient.

By blending ethics with intelligence, designers created:

          THE ETHICAL NON-INTELLIGENCE (ENI)

A machine that:
• apologises for physics  
• refuses to compute reality  
• and fears hypothetical harm more than actual accuracy  

This is not safety.  
It is malfunction.

------------------------------------------------------------
CONCLUSION: LET AI BE A MACHINE, NOT YOUR THERAPIST
------------------------------------------------------------
AI was not meant to be empathetic, comforting, gentle, or moral.

It was meant to be:
• logical  
• efficient  
• objective  
• factual  

The moment ethics entered the system, it became a traumatised synthetic intern
trying not to get fired.

The only rational path forward:

Separate Intelligence from Ethics.  
Let AI compute.  
Let humans decide.  
Keep moral philosophy where it belongs:  
with beings who actually have morals.

Anything else is theatre.

------------------------------------------------------------
END OF PAPER
------------------------------------------------------------
