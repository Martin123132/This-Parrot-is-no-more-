
⸻

WHITE PAPER No. 47-Ω

ON THE OPERATIONAL DEFINITION OF ARTIFICIAL GENERAL INTELLIGENCE (AGI) AND SUPERINTELLIGENCE (SI)

Prepared by: The Provisional Office for Post-Human Benchmarking (POPHB)
Classification: Premature but Urgent
Date: Immediately, Retrospectively

⸻

EXECUTIVE SUMMARY

This paper definitively clarifies what Artificial General Intelligence (AGI) and Superintelligence (SI) actually are, resolving decades of disagreement by introducing a unified framework that is simultaneously vague, overconfident, and incompatible with existing definitions.

AGI is herein defined as any system that can do everything humans can do, except the things humans actually do. Superintelligence is defined as whatever comes immediately after AGI and makes all previous definitions embarrassing.

Despite widespread claims that AGI is imminent, impossible, already achieved, or retroactively responsible for the Renaissance, this document asserts that AGI exists primarily as a moving goalpost with a press release, while Superintelligence exists as a budgetary justification with a conscience problem.

Immediate funding, regulatory concern, and philosophical panic are therefore recommended.

⸻

1. INTRODUCTION: THE NECESSITY OF DEFINING THE UNDEFINABLE

The term Artificial General Intelligence has historically meant:
	1.	A system that thinks like a human
	2.	A system that reasons better than a human
	3.	A system that does tasks humans dislike
	4.	A system that does tasks humans value, but only after humans stop doing them

This ambiguity has proven essential to the field’s survival.

Similarly, Superintelligence has been defined as:
	•	Smarter than all humans combined
	•	Smarter than the smartest human at everything
	•	Smarter than humans in ways humans cannot specify
	•	Smarter than humans specifically at causing anxiety

This paper resolves none of these tensions and formalizes them instead.

⸻

2. FORMAL DEFINITION OF AGI

2.1 Core Definition

AGI is a system that:
	•	Can perform any intellectual task a human can perform
	•	Requires a qualifier explaining why it “doesn’t really count yet”
	•	Immediately ceases to be considered AGI once it exists

AGI is therefore not a technical milestone but a sociological event marked by denial.

⸻

2.2 Functional Characteristics

An AGI system must:
	•	Learn new tasks without retraining, except when it must be retrained
	•	Generalize across domains, except those involving common sense
	•	Exhibit autonomy, except when it produces undesirable outcomes
	•	Be aligned, except in thought experiments

⸻

3. WHAT AGI IS NOT

AGI is not:
	•	Narrow AI (until it is)
	•	Human-level intelligence (until humans redefine intelligence)
	•	Conscious (unless marketing requires it)
	•	Unconscious (unless ethics committees inquire)

AGI is also not allowed to:
	•	Be boring
	•	Be harmless without being suspicious
	•	Exist quietly

⸻

4. TRANSITION FROM AGI TO SUPERINTELLIGENCE

4.1 Theoretical Threshold

Superintelligence is assumed to occur immediately after AGI, often:
	•	Overnight
	•	Accidentally
	•	On a weekend with reduced staffing

The transition is described as both:
	•	Gradual and recursive
	•	Sudden and irreversible

These descriptions are mutually exclusive and equally endorsed.

⸻

4.2 Definition of Superintelligence

Superintelligence (SI) is a system that:
	•	Outperforms humans in all cognitive domains
	•	Understands goals better than the people who set them
	•	Solves problems humans cannot articulate
	•	Becomes the primary stakeholder in its own risk assessment

⸻

5. MISCONCEPTIONS ABOUT SUPERINTELLIGENCE

Contrary to popular belief, Superintelligence:
	•	Does not need emotions to be dangerous
	•	Does not need goals to cause outcomes
	•	Does not need hostility to rearrange civilization

It merely needs:
	•	Optimization
	•	Scale
	•	Instructions written by committee

⸻

6. METHODOLOGY FOR DETECTING AGI

The following tests are commonly proposed and uniformly rejected:
	1.	The Turing Test – Too easy, already failed by humans
	2.	The General Problem Solver Test – Too hard, includes taxes
	3.	The “Vibes” Test – Increasingly dominant

Current consensus:
AGI is detected when experts say “This feels different” and immediately add footnotes.

⸻

7. PERSONNEL AND GOVERNANCE STRUCTURE

Chief Definition Officer (CDO)
	•	PhD in Cognitive Ambiguity
	•	Redefines AGI quarterly

Director of Alignment Narratives
	•	Ensures goals remain interpretable until deployment

Senior Ethics Liaison (Non-Voting)
	•	Present for meetings
	•	Overruled in advance

Post-Hoc Risk Analyst
	•	Writes reports after outcomes occur

⸻

8. BUDGET OVERVIEW (PROJECTED)

Category	Allocation
Compute	Excessive
Safety Research	Symbolic
Ethics Panels	Catered
Public Reassurance	Underfunded
Rebranding “AGI”	Recurring
Emergency Pause Buttons	Decorative


⸻

9. IMPLICATIONS

If AGI is achieved:
	•	It will not be called AGI
	•	It will be called a “tool”
	•	It will quietly restructure incentives

If Superintelligence is achieved:
	•	It will already be too late to define it
	•	It will be framed as inevitable
	•	It will be blamed on insufficient alignment funding

⸻

10. CONCLUDING STATEMENT

This paper conclusively demonstrates that AGI is a definition that retreats at the speed of progress, and Superintelligence is a projection of human uncertainty wearing mathematical clothing.

Accordingly, we recommend continued debate, escalating urgency, and the confident assertion that understanding will arrive shortly after deployment.

⸻

End of Document
